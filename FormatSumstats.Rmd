---
title: "FormatSumstats"
author: "Alan Murphy"
date: "Most recent update:<br> `r Sys.Date()`"
output: 
  rmarkdown::html_document: 
    theme: spacelab
    highlight: zenburn 
    code_folding: show 
    toc: true 
    toc_float: true
    smooth_scroll: true
    number_sections: false 
    self_contained: true 
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=T, message=F}
#root.dir <- here::here()
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  #root.dir = root.dir
  fig.height = 15,
  fig.width = 16
)  
knitr::opts_knit$set(#root.dir = root.dir, 
                     dpi = 300)  

library(data.table)
library(ggplot2)
library(cowplot)
library(stringr)
```

## Background

SumstatsFormats builds upon the work of the [gwas-download](https://github.com/mikegloudemans/gwas-download) repository which created a script to download publicly available GWAS summary statistics from over 200 different publications. If you want to run the code yourself please first run the download script from this repository and set your working directory to this repository's folder.

The aim of this analysis is to give insight into the most frequent format of summary statistic files from GWAS. If you want to run the code yourself please first run the download script from [gwas-download](https://github.com/mikegloudemans/gwas-download) and set your working directory to this repository's folder.

## Acquire GWAS Summary Statistic formats

*NOTE* this section will only run if you have ran the gwas-download script and set it's folder as the working directory. I have saved the results of this section in this repository so the subsequent analysis can still be run.

Load required packages for analysis
```{r}

```

First we need to collect all the summary statistic file headers from the 200+ GWAS. Note that each GWAS has more than one associated summary statistic file.

```
files <- list.files(path = "download", full.names = TRUE, recursive = TRUE)
print(head(files))
```
To get all the summary statistic file headers we need to inspect

 * gunzipped files (.gz)
 * zipped files (.zip)
 * text files (.txt)

Each of these will be dealt with separately 
```
#gunzipped files
files_gz <- files[grep(".gz$", files)]

headers_gz <- vector(mode="character",length=length(files_gz))
names(headers_gz) <- files_gz

# Unzip the file into the dir
for(file_i in files_gz){
  #only add header if one is found
  if(length(readLines(file_i,n=1))!=0)
    headers_zip[[file_i]] <- readLines(file_i,n=1)#n=number of lines to read
}
#remove empties
headers_gz <- headers_gz[headers_gz!=""]


#zipped files
files_zip <- files[grep(".zip$", files_zip)]
zip_headers <- c()
count1 <- 1
# Unzip the file into the dir
for(file_i in files_zip){
  breaker<-FALSE
  #some don't want to open, if this happens skip them
  possibleError <- tryCatch(unzip(file_i,list=TRUE),error=function(e) e)
  if(inherits(possibleError, "error"))
    breaker=TRUE
  if(isFALSE(breaker)){
    items_file_i<-unzip(file_i,list=TRUE)
    #remove READMEs
    zip_files_i <-
      items_file_i$Name[!grepl("README", items_file_i$Name, fixed = TRUE)]
    counting <- 1
    for(zip_i in zip_files_i){
      possibleError2 <- tryCatch(readLines(unzip(file_i,files=zip_i),n=1),
                                 error=function(e) e)
      if(!inherits(possibleError2, "error")){
        a<-readLines(unzip(file_i,files=zip_i),n=1)
        if(a=="%PDF-1.4"||a==""){#not correct file
          #do nothing
          counting <- counting+1
        }
        else{
          zip_headers <- c(zip_headers,a)
          names(zip_headers)[count1] <- paste0(file_i,counting)
          counting <- counting+1
          count1 <- count1+1
        }
      }
    }
  }
}


#text files
files_txt <- files[grep(".txt$", files)]
#remove READMEs anmd other odd formats that will wreck downstream analysis
files_txt <- files_txt[!grepl("README", files_txt, fixed = TRUE)]
files_txt <- files_txt[!grepl("Readme", files_txt, fixed = TRUE)]

headers_txt <- vector(mode="character",length=length(files_txt))
names(headers_txt) <- files_txt

# Read the file
for(file_i in files_txt){
  #only add header if one is found
  if(length(readLines(file_i,n=1))!=0)
    headers_txt[[file_i]] <- readLines(file_i,n=1)#n=number of lines to read
}
#remove empties
headers_txt <- headers_txt[headers_txt!=""]

headers_combined <- c(headers_txt,headers_gz,zip_headers)
#change directory to SumstatFormat
save(headers_combined, file="data/SumstatHeaders.rda")
```

## Analysis GWAS Summary Statistic formats

Now that the headers are derived for each file type, we can combine then and check how many unique headers there are:

```{r}
load(file="data/SumstatHeaders.rda")
print(length(headers_combined))
```

```{r}
tbl_headers <- table(headers_combined) 

dt_headers <- data.table::data.table("header"=names(tbl_headers),
                                     "counts"=as.numeric(tbl_headers))
print(nrow(dt_headers))
```

There were *327* headers from the combined file types and *127* unique formats for the summary statistic files.

This shows the clear disparity across GWAS studies. We can plot and inspect the top 12 most common headers:

```{r}
top12 <- dt_headers[counts>=sort(dt_headers$counts,decreasing=TRUE)[12],]

print(sum(top12$counts)/sum(dt_headers$counts)) 
```

The top 12 headers account for ~ 47% of all summary statistic files. We can see these and their distribution by plotting:

```{r}
#wrap headers to make them readable
#issue with first entry and wrap text since it has "\" so using
top12[,plot_header:=str_wrap(iconv(enc2utf8(top12$header),sub="byte"), 
                              width = 50)]

ggplot(data=top12,
       aes(x = reorder(plot_header, counts),y = counts, fill=counts))+
  geom_bar(stat="identity")+
  geom_text(aes(label = scales::percent((counts/sum(dt_headers$counts)))),
              hjust = -0.05)+
  labs(y= "Number of GWAS with this header", x = "Summary Statistics Headers") +
  theme_cowplot()+
  theme(axis.text = element_text(size=12), axis.title = element_text(size=12),
          legend.text=element_text(size=10),legend.title=element_text(size=12))+
  scale_fill_continuous(high = "#132B43", low = "#56B1F7")+
  coord_flip()
```

We can then save this plot:

```{r Save plot}
ggplot2::ggsave(filename = here::here("plots/SumstatsFormats.pdf"),
                height = 15,
                width = 16,
                dpi = 300)
```


## Future work

The SumstatFormats analysis highlights the disparity across summary statistic files, creating a barrier major to automated meta-analysis studies. There has been a push recently to standardise summary statistic files. For example, there is a group who have now manually standardised many GWAS: [R interface to the IEU GWAS database API â€¢ ieugwasr](https://mrcieu.github.io/ieugwasr/) and [gwasvcf](https://github.com/MRCIEU/gwasvcf) but because a lot of GWAS
remain closed access, these repositories are not all encompassing. Moreover, the use of VCF format for summary statistics seen increased use but older GWAS still need a method of intgration with these for meta-analysis. 

To address this issue, the bioconductor R package *MungeSumstats* was created to standardise the file format of summary statistic files, including VCF files. See the [MungeSumstats](https://github.com/neurogenomics/MungeSumstats) github page for more details.